{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect Data\n",
    "\n",
    "Here, all necessary data is retrieved and aggregated.  The resulting dataframes are then engineered as necessary and exported as csv files for later use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Packages and define utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import datetime\n",
    "import requests\n",
    "pd.options.display.max_columns = 100\n",
    "pd.options.display.max_rows = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility functions\n",
    "\n",
    "# returns the time difference between now and a date given as a string\n",
    "def host_dur(t):\n",
    "    if str(t) == \"nan\":\n",
    "        return np.nan\n",
    "    t = np.datetime64(str(t))\n",
    "    delt = np.datetime64(datetime.datetime.now()) - t\n",
    "    delt_int = np.timedelta64(delt, 'D').astype(int)\n",
    "    return delt_int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate urls and read in all data\n",
    "\n",
    "Note: All data is collected from insideairbnb.com.  Only data from Boston is used for this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate urls\n",
    "start = \"http://data.insideairbnb.com/united-states/ma/boston/\"\n",
    "list_end = \"/data/listings.csv.gz\"\n",
    "cal_end = \"/data/calendar.csv.gz\"\n",
    "dates = ['2015-10-03', '2016-09-07', '2017-10-06', '2018-04-14', '2018-05-17', '2018-07-18', '2018-08-17', '2018-09-14', '2018-10-11']\n",
    "list_urls = list(map(lambda d: start + d + list_end, dates))\n",
    "cal_urls = list(map(lambda d: start + d + cal_end, dates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading listing urls...\n",
      "Reading calendar urls...\n",
      "Concatenating data...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# read in, append data, and write full tables to csv\n",
    "\n",
    "all_listings = []\n",
    "all_calendar = []\n",
    "\n",
    "print(\"Reading listing urls...\")\n",
    "for l in list_urls:\n",
    "    data = pd.read_csv(l)\n",
    "    all_listings.append(data)\n",
    "\n",
    "print(\"Reading calendar urls...\")\n",
    "for c in cal_urls:\n",
    "    data = pd.read_csv(c)\n",
    "    all_calendar.append(data)\n",
    "\n",
    "print(\"Concatenating data...\")\n",
    "list_df = pd.concat(all_listings, axis=0, ignore_index=True, sort=True)\n",
    "cal_df = pd.concat(all_calendar, axis=0, ignore_index=True, sort=True)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean and engineer data\n",
    "\n",
    "Generated features include:\n",
    "* is_professional -- whether or not a host is a professional host\n",
    "* n_amenities -- the number of amenities a listing has\n",
    "* occ_rate -- the occupancy rate of a listing during the year that it was scraped from\n",
    "* host_dur -- the length of time that a listings host has been a host\n",
    "* n_pchange -- the number of price changes of a listing during the year that it was scraped from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning and engineering listing features...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Cleaning and engineering listing features...\")\n",
    "\n",
    "# engineer feature 'is_professional'\n",
    "list_df['is_professional'] = 0\n",
    "list_df.is_professional.loc[list_df[\"host_total_listings_count\"] > 1] = 1\n",
    "\n",
    "# engineer feature 'number of amenities'\n",
    "list_df['n_amenities'] = list_df.amenities.map(lambda x: len(x))\n",
    "\n",
    "# clean columns by removing '$'\n",
    "list_df['cleaning_fee'] = list_df['cleaning_fee'].str.replace('$', '').apply(pd.to_numeric)\n",
    "list_df['extra_people'] = list_df['extra_people'].str.replace('$', '').apply(pd.to_numeric)\n",
    "list_df['monthly_price'] = list_df['monthly_price'].str.replace('$', '').str.replace(',', '').apply(pd.to_numeric)\n",
    "list_df['price'] = list_df['price'].str.replace('$', '').str.replace(',', '').apply(pd.to_numeric)\n",
    "list_df['weekly_price'] = list_df['weekly_price'].str.replace('$', '').str.replace(',', '').apply(pd.to_numeric)\n",
    "list_df['security_deposit'] = list_df['security_deposit'].str.replace('$', '').str.replace(',', '').apply(pd.to_numeric)\n",
    "\n",
    "# convert percentage to decimal\n",
    "list_df['host_acceptance_rate'] = list_df['host_acceptance_rate'].str.replace('%', '').apply(pd.to_numeric).map(lambda x: x / 100)\n",
    "list_df['host_response_rate'] = list_df['host_response_rate'].str.replace('%', '').apply(pd.to_numeric).map(lambda x: x / 100)\n",
    "\n",
    "# engineer feature 'host_length'\n",
    "list_df['host_dur'] = list_df.host_since.map(lambda x: host_dur(x))\n",
    "\n",
    "# change zipcode feature\n",
    "list_df['zipcode'] = list_df['zipcode'].apply(str)\n",
    "\n",
    "# add year feature\n",
    "list_df['year'] = list_df.last_scraped.map(lambda x: x[0:4]).astype(int)\n",
    "\n",
    "# rename listing id feature\n",
    "list_df['listing_id'] = list_df['id']\n",
    "list_df = list_df.drop(['id'], axis=1)\n",
    "\n",
    "# drop unwanted columns\n",
    "bad_features = ['license', 'security_deposit', 'square_feet', 'last_scraped', 'weekly_price', 'monthly_price', 'host_acceptance_rate', 'neighbourhood', 'scrape_id','host_id', 'availability_30', 'availability_365', 'availability_60', 'availability_90', \"access\", \"amenities\", \"calendar_last_scraped\", \"calendar_updated\", \"city\", \"country\", \"country_code\", \"description\", \"experiences_offered\", \"first_review\", \"host_about\", \"host_identity_verified\", \"host_location\", \"host_name\", \"host_neighbourhood\", \"host_picture_url\", \"host_response_time\", \"host_since\", \"host_thumbnail_url\", \"host_url\", \"host_verifications\", \"house_rules\", \"interaction\", \"is_business_travel_ready\", \"is_location_exact\", \"jurisdiction_names\", \"last_review\", \"listing_url\", \"market\", \"medium_url\", \"name\", \"neighborhood_overview\", \"neighbourhood\", \"neighbourhood_group_cleansed\", \"notes\", \"picture_url\", \"require_guest_phone_verification\", \"require_guest_profile_picture\", \"requires_license\", \"smart_location\", \"space\", \"state\", \"street\", \"summary\", \"thumbnail_url\", \"transit\", \"xl_picture_url\"]\n",
    "list_df = list_df.drop(bad_features, axis=1)\n",
    "list_df = list_df.dropna()\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning calendar data...\n",
      "Engineering calendar features...\n",
      "Generating price changes...\n",
      "Reformatting calendar dataframe...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# NOTE: takes a while\n",
    "\n",
    "print(\"Cleaning calendar data...\")\n",
    "# remove $ from price column\n",
    "cal_df['price'] = cal_df['price'].str.replace('$', '').str.replace(',','').apply(pd.to_numeric)\n",
    "cal_df['available'] = cal_df['available'].str.replace('f', '0').str.replace('t', '1').astype(int)\n",
    "\n",
    "# make a copy before engineering\n",
    "cal_raw = cal_df.copy(deep=True)\n",
    "\n",
    "print(\"Engineering calendar features...\")\n",
    "# generate occupancy rate\n",
    "cal_df['year'] = cal_df.date.map(lambda x: x[0:4])\n",
    "cal_count = cal_df.groupby(['listing_id', 'year']).count()\n",
    "cal_count['occ_rate'] = cal_count.price / cal_count.available\n",
    "cal_count = cal_count.reset_index()\n",
    "\n",
    "print(\"Generating price changes...\")\n",
    "# generate price changes\n",
    "cal_nunique = cal_df.groupby(['listing_id', 'year']).nunique()\n",
    "\n",
    "print(\"Reformatting calendar dataframe...\")\n",
    "# reformat dataframe\n",
    "cal_df = pd.DataFrame(data={'listing_id': cal_count['listing_id'].values, \n",
    "                        'year': cal_count['year'].values,\n",
    "                        'occ_rate': cal_count['occ_rate'].values, \n",
    "                        'n_pchange':cal_nunique['price'].values})\n",
    "cal_df['year'] = cal_df['year'].astype(int)\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge dataframes and write to .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging dataframes...\n",
      "Changing year column...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Merging dataframes...\")\n",
    "# merge dataframes\n",
    "df = list_df.merge(cal_df, on=['listing_id', 'year'], how='left')\n",
    "\n",
    "print(\"Changing year column...\")\n",
    "# change year column to year since\n",
    "df['year_since'] = df['year'] - df['year'].min()\n",
    "df = df.drop('year', axis=1)\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = str(Path().resolve())\n",
    "df.to_csv(dir + \"/../data/listings.csv\", index=False)\n",
    "list_df.to_csv(dir + \"/../data/list_df.csv\", index=False)\n",
    "cal_raw.to_csv(dir + \"/../data/cal_df.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
