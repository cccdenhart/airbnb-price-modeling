{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Price Change Effects\n",
    "Using the reshaped listing price data, the average daily revenue change resulting from a price change is predicted using KNN, a random forest, and a feed-forward neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages and load in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score \n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "import keras.callbacks as cb\n",
    "from pathlib import Path\n",
    "pd.options.display.max_columns = 100\n",
    "pd.options.display.max_rows = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "dir = str(Path().resolve())\n",
    "pc_df = pd.read_csv(dir + \"/../data/price_changes.csv\")\n",
    "list_df = pd.read_csv(dir + \"/../data/list_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename listing id column\n",
    "list_df['id'] = list_df['listing_id']\n",
    "list_df = list_df.drop('listing_id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging dataframes...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Merging dataframes...\")\n",
    "# merge dataframes\n",
    "df = pc_df.merge(list_df, on=['id', 'year'], how='left')\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows with missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# drop listing id\n",
    "df = df.drop('id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df shape:  (5230391, 43)\n"
     ]
    }
   ],
   "source": [
    "print(\"df shape: \", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_adr(x):\n",
    "    if x > 0.0:\n",
    "        return 0\n",
    "    elif x < 0.0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bin revenue\n",
    "df['revenue_change'] = df.revenue_change.apply(bin_adr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting into X and y...\n",
      "Getting dummy values...\n",
      "Splitting into train and test...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Splitting into X and y...\")\n",
    "# split into X and y\n",
    "y = df['revenue_change']\n",
    "X = df.drop('revenue_change', axis=1)\n",
    "\n",
    "# manually select columns to drop\n",
    "X = X.drop(['calculated_host_listings_count', 'host_listings_count', 'last_scraped', 'latitude', 'longitude', 'review_scores_checkin', 'review_scores_accuracy', 'review_scores_cleanliness', 'review_scores_communication', 'review_scores_location', 'review_scores_rating'], axis=1)\n",
    "\n",
    "print(\"Getting dummy values...\")\n",
    "# get dummy values\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "print(\"Splitting into train and test...\")\n",
    "# split into training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training random forest...\")\n",
    "rf = RandomForestClassifier(n_estimators=50).fit(X_train, y_train)\n",
    "print(\"Predicting random forest...\")\n",
    "rf_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert y values\n",
    "nn_train = np_utils.to_categorical(y_train, 3)\n",
    "nn_test = np_utils.to_categorical(y_test, 3)\n",
    "\n",
    "# initialize feed-forward neural network\n",
    "print(\"Initializing network...\")\n",
    "ffnn = Sequential()\n",
    "ffnn.add(Dense(units=12, activation='relu', input_dim=20))\n",
    "ffnn.add(Dropout(0.2))\n",
    "ffnn.add(Dense(units=10, activation='exponential'))\n",
    "ffnn.add(Dropout(0.2))\n",
    "ffnn.add(Dense(units=8, activation='sigmoid'))\n",
    "ffnn.add(Dropout(0.2))\n",
    "ffnn.add(Dense(units=3, activation='relu'))\n",
    "\n",
    "# compile model\n",
    "print(\"Compiling model...\")\n",
    "ffnn.compile(loss=categorical_crossentropy, optimizer=SGD(lr=0.01, momentum=0.9, nesterov=True))\n",
    "\n",
    "# fit model\n",
    "print(\"Fitting model...\")\n",
    "ffnn.fit(X_train, nn_train, epochs=10, batch_size=128, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get ffnn predictions\n",
    "ffnn_preds = ffnn.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RF Results:\")\n",
    "print(\"accuracy: \" + str(accuracy_score(y_test, rf_pred)))\n",
    "print(\"precision: \" + str(precision_score(y_test, rf_pred, average=None)))\n",
    "print(\"recall: \" + str(recall_score(y_test, rf_pred, average=None)))\n",
    "print()\n",
    "print(\"FFNN Results:\")\n",
    "print(\"accuracy: \" + str(accuracy_score(y_test, ffnn_preds)))\n",
    "print(\"precision: \" + str(precision_score(y_test, ffnn_preds, average=None)))\n",
    "print(\"recall: \" + str(recall_score(y_test, ffnn_preds, average=None)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "One contribution to the mediocre results could be the fact that there are significantly more \"no change\" observations than the other two.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.bincount(y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
